// Attributes
:walkthrough: Knative Serving + Camel K
:title: Lab 2 - {walkthrough}
:user-password: openshift
:standard-fail-text: Verify that you followed all the steps. If you continue to have issues, contact a workshop assistant.
:namespace: {user-username}

// URLs
:openshift-streams-url: https://console.redhat.com/beta/application-services/streams/kafkas
:next-lab-url: https://tutorial-web-app-webapp.{openshift-app-host}/tutorial/dayinthelife-streaming.git-labs-02-/
:codeready-url: http://codeready-codeready.{openshift-app-host}/

ifdef::env-github[]
:next-lab-url: ../02-xxx/walkthrough.adoc
endif::[]

[id='knative-serving-camel-k']
= {title}

XXXXXXXX TBD

*Audience:* Enterprise Integrators, System Architects, Developers, API Designers, Data Integrators

*Overview*

XXXXXXXX TBD

image::images/lab1-overview.png[Overview, role="integr8ly-img-responsive"]

Red Hat Integration includes an integration Platform-as-a-Service (iPaaS) solution that makes it easy for business users to collaborate with integration experts and application developers. It is a full toolchain and runtime, available right from your browser. You will use this tool to design and implement a new API service and to connect with the Event bus provided by AMQ Online.

*Why Red Hat?*

The Red Hat portfolio of middleware products helps you create a unified environment for application development, delivery, integration, and automation. It is comprised of comprehensive frameworks, integration solutions, process automation, runtimes, and programming languages.

To respond to business demands quickly and efficiently, you need a way to integrate applications and data spread across your enterprise. Red Hat AMQ —based on open source communities like Apache ActiveMQ and Apache Kafka— is a flexible messaging platform that delivers information reliably, enabling real-time integration and connecting the Internet of Things (IoT).

AMQ Online is a solution (Operator) to manage multiple components to provide the overall functionality of running self-service (Messaging as a Service) messaging platform on OpenShift. With AMQ online, developers can provision messaging when and where they need it through a browser console. The AMQ online component is built on the foundation of Red Hat OpenShift, a container platform for high scalability and availability of cloud-native applications.

*Credentials*

Use the following credentials to login into the web consoles:

* Your *username* is: `{user-username}`
* Your *password* is: `{user-password}`

[type=walkthroughResource,serviceName=codeready]
.Red Hat CodeReady Workspaces
****
* link:{codeready-url}[Console, window="_blank", , id="resources-codeready-url"]
****
[type=walkthroughResource]
.Red Hat OpenShift Developer Console
****
* link:{openshift-host}/topology/ns/{namespace}[Topology View, window="_blank"]
****
[type=walkthroughResource]
.Red Hat OpenShift Application Services
****
* link:{openshift-streams-url}[Streams for Apache Kafka, window="_blank"]
****

:sectnums:

[time=5]
[id="Getting Ready"]
== Getting ready for the labs

[IMPORTANT]
====
Please complete the following instructions to get ready for this lab. *If this is not the first lab you are doing today, and you have already completed this step in any of the previous labs, please skip to next task*.
====


One of the main features of Knative is automatic scaling of replicas for an application to closely match incoming demand, including scaling applications to zero if no traffic is being received. The Autoscaler component watches traffic flow to the application, and scales replicas up or down based on configured metrics.


=== Start CodeReady workspace

. Once you have logged in and authorized access to your user account, you will land in your personal CodeReady dashboard.
+
--
A new workspace has been configured with the required tools, plugins and project to start working on this workshop.

Click on the workspace with the name starting with `dil-serverless-` on the left menu bar under *RECENT WORKSPACES*.

image::images/codeready-dashboard.png[CodeReady Dashboard, role="integr8ly-img-responsive"]

[NOTE]
====
You can also click on the name of the workspace in the center, and then click on the green button that says _Open_ on the top right hand side of the screen.
====
--

. This will start an instance of the workspace. Please wait a few moments while it downloads the required container images and configuration setup.
+
image::images/codeready-loading.png[Loading CodeReady, role="integr8ly-img-responsive"]

. The first time it's run, it will git clone the required projects for this workshop. After a minute or two, you’ll be placed in the workspace. Close the initial welcome and Readme tabs then click on the Explorer button on the left side bar.
+
image::images/codeready-welcome.png[CodeReady Welcome screen, role="integr8ly-img-responsive"]
+
[NOTE]
====
This IDE is based on *Code Ready*, which is in turn is based on Microsoft VS Code editor. It will look familiar if you have already used it.

You can close the _Problems_ and _Output_ views to clear space.
====

. The projects explorer will show you the *dil-serverless* folder with the required projects. Expand the folders to reveal the projects we cloned from the git repository.
+
image::images/codeready-projects.png[Workshop projects, role="integr8ly-img-responsive"]

. During the workshop we will need to introduce commands for both the OpenShift and other Command Line Interfaces (CLI) tools. For that we will need to start a terminal window _inside_ one of the containers from the developer workspace. To open the terminal window, click on the _My Workspace_ button on the right side panel and expand the **User Runtimes/tools** folder. Click on *>_ New terminal*.
+
image::images/codeready-new-terminal.png[Open Terminal, role="integr8ly-img-responsive"]

. This will deploy the terminal window in the bottom of the screen. This terminal is attached to the running CodeReady container and is also running on OpenShift. This is the place where you will issue most of the commands from this workshop.
+
image::images/codeready-terminal.png[CodeReady Terminal, role="integr8ly-img-responsive"]

=== Login into the OpenShift cluster

. Finally, you will need to login into the OpenShift CLI to start interacting with the platform. For login, issue the following command:
+
[source,bash,subs="attributes+"]
----
oc login -u {user-username} -p {user-password} https://$KUBERNETES_SERVICE_HOST:$KUBERNETES_SERVICE_PORT --insecure-skip-tls-verify=true
----

. You should see something like the following (the project names may be different):
+
----
Login successful.

You have access to the following projects and can switch between them with 'oc project <projectname>':

  * {namespace}
    {namespace}-codeready
    {namespace}-dayinthel-0605

Using project "{user-username}".
Welcome! See 'oc help' to get started.
----

. Most of the work will be deploy to your own `{namespace}` project namespace, so be sure to have it as a _working_ project by executing the following command:
+
[source,bash,subs="attributes+"]
----
oc project {namespace}
----

. Now you are ready to start working on the application services.


[time=10]
[id="Serving with API"]
== Knative Serving, Camel K & API



We are ready to go over the application to validate the previous statements. We will order some different flavors by calling our RESTful backend services, plus check how the application behaves in case of failure.

=== Creating the API

Create the API
Take a look at the API

. title: Meter API
. Path /meter/status

. Setup the schema, with name *meterstatus*

[source,json,role="copypaste"]
----
      {
        "key": "F6PeB2XQRYG-8EN5yFcrP",
        "value": {"meterId":"F6PeB2XQRYG-8EN5yFcrP","timestamp":'$TIMESTAMP',"status":"unknown"}
      }
----

. *200* OK status update

* _operationId_: create
* _summary_: update meter status
* _description_: update meter status
* _content_: application/json


. Export the API using *yaml*
. Copy & Paste the content from the downloaded file into *openapi-spec.yaml*

 Camel K makes running serverless easy.

. Go back to the CodeReady Workspaces IDE
. API to DB, Find MeterConsumer.java
. Paste following code in the //PASTE HERE

[source,java,role="copypaste"]
----
        from("direct:create").routeId("MetersFromAPI")
            .throttle(3).timePeriodMillis(20000)
            .unmarshal().json()
            .setHeader("meterId",simple("${body.[value][meterId]}"))
            .setHeader("status",simple("${body.[value][status]}"))
            .setBody(simple("INSERT INTO meter_update(meter_id, timestamp, status_text) VALUES ('${headers.meterId}', to_timestamp(${body.[value][timestamp]}), '${headers.status}');"))
            .log("SQL INSERT statement: ${body}")
            .to("jdbc:dataSource")
----

. View the _meter.properties_ and create it by running
[source,bash,role="copypaste"]
----
oc create configmap amqp-properties --from-file $CHE_PROJECTS_ROOT/dil-serverless/lab-01/meters.properties -n {namespace}
----


. Start up the API as a serverless function by running in the terminal
[source,bash,role="copypaste"]
----
oc project {namespace}

kamel run MeterConsumer.java

oc patch -n user1 ksvc/events -p '{ "metadata" : { "annotations" : { "app.openshift.io/connects-to" : "iot-psql" } }'

----

. Go to OpenShift Developer Topology, see the meter-consumer starts up.
. In the CodeReady terminal, send a request to make sure everything works correctly
[source,bash,role="copypaste"]
----
TIMESTAMP=`date +%s`
curl -X POST \
http://meter-consumer-user1.apps.cluster-3bc2.3bc2.example.opentlc.com/meter/status \
-H 'content-type: application/json' \
-d '
     {
        "key": "F6PeB2XQRYG-8EN5yFcrP",
        "value": {"meterId":"F6PeB2XQRYG-8EN5yFcrP","timestamp":'$TIMESTAMP',"status":"unknown"}
      }
'
----

. View the inserted result, from the database
[source,bash,role="copypaste"]
----
oc exec $(oc get pods -o custom-columns=POD:.metadata.name --no-headers -l app=iot-psql) -- bash -c 'psql -d $POSTGRES_DB -U $POSTGRES_USER -c "select * from meter_update;"'
----

. Wait for couple of minutes, go back to OpenShift Developer Topology and see pod now scale downs to ZERO

. In the CodeReady terminal, send another request, and see the pod comes back up again
[source,bash,role="copypaste"]
----
TIMESTAMP=`date +%s`
curl -X POST \
http://meter-consumer-user1.apps.cluster-3bc2.3bc2.example.opentlc.com/meter/status \
-H 'content-type: application/json' \
-d '
     {
        "key": "F6PeB2XQRYG-8EN5yFcrP",
        "value": {"meterId":"F6PeB2XQRYG-8EN5yFcrP","timestamp":'$TIMESTAMP',"status":"unknown"}
      }
'
----

[type=verification]
Were you able to successfully scale-down and scale-up your application?

[type=verificationFail]
{standard-fail-text}

[time=5]
== Create a Kafka Topic

. Open the link:{openshift-streams-url}[OpenShift Streams Console, window="_blank"].
. Click name of the Kafka cluster you created in the previous lab,e.g `{user-username}-kafka`. This will display the Topics list.
. Click the *Create Topic* button
.. Enter `hydrated-meter-events` for the topic name, and click *Next*.
.. Set the number of partitions to 3, and click *Next*.
.. Leave the message retention settings at the default values, and click *Next*.
.. The in-sync replicas is hardcoded to 2 of 3.
. Click *Finish* to create the topic.

== Deploy HTTP Kafka Bridge

. Open a terminal in CodeReady Workspaces.
. Login to the OpenShift CLI using the following command:
+
[source,bash,subs="attributes+"]
----
oc login -u {user-username} -p {user-password} https://$KUBERNETES_SERVICE_HOST:$KUBERNETES_SERVICE_PORT --insecure-skip-tls-verify=true
----
. Select the `{user-username}` project:
+
[source,bash,subs="attributes+"]
----
oc project {user-username}
----
. Create a secret containing your Service Account's *Client Secret*. You obtained this from the link:{openshift-streams-url}[OpenShift Streams Console, window="_blank"] in the previous lab.
+
[source,bash,subs="attributes+"]
----
echo -n "client-id-goes-here" > /tmp/client-secret.txt
oc create secret generic kafka-client-secret \
--from-file=password=/tmp/secret.txt
----
. Create a file named *bridge.yaml* file in your CodeReady workspace. Paste the following content into the file:
+
[source,yaml,subs="attributes+",role="copypaste"]
----
apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaBridge
metadata:
  name: kafka-bridge
  namespace: {user-username}
spec:
  bootstrapServers: REPLACE_ME
  http:
    port: 8080
  replicas: 1
  authentication:
    type: plain
    username: REPLACE_ME
    passwordSecret:
      secretName: kafka-client-secret
      password: password
  tls:
    enable: true
    caCert: {}
    cert: {}
    key: {}
----
. Replace the *spec.bootstrapServers* with the Bootstrap Server URL from the link:{openshift-streams-url}[OpenShift Streams Console, window="_blank"].
. Replace the *authentication.username* with your Service Account's *Client ID* that you obtained in the previous lab.
. Apply this YAML to your OpenShift Project:
+
[source,bash,subs="attributes+"]
----
oc apply -f bridge.yaml
----
. Wait for the Kafka Bridge Pod to enter a *Running* status. You can watch it's status using this command:
+
[source,bash,subs="attributes+"]
----
oc get pods -l app.kubernetes.io/name=kafka-bridge -w
----

== API to Eventing

. In CodeReady add the following code to the end of route,

[source,java,subs="attributes+"]
----
    .setBody(simple("SELECT address, id as meter_id, '${headers.status}' as status_text , latitude, longitude FROM meter where id = '${headers.meterId}' ;"))
    .log("SQL SELECT statement: ${body}")
    .to("jdbc:dataSource")
    .marshal().json()
    .to("kafka:{{consumer.topic}}?brokers={{kafka.host}}:{{kafka.port}}")
----
so it would look like this,
[source,java,subs="attributes+"]
----
    from("direct:create").routeId("MetersFromAPI")
            .throttle(3).timePeriodMillis(20000)
            .unmarshal().json()
            .setHeader("meterId",simple("${body.[value][meterId]}"))
            .setHeader("status",simple("${body.[value][status]}"))
            .setBody(simple("INSERT INTO meter_update(meter_id, timestamp, status_text) VALUES ('${headers.meterId}', to_timestamp(${body.[value][timestamp]}), '${headers.status}');"))
        .log("SQL INSERT statement: ${body}")
            .to("jdbc:dataSource")
            .setBody(simple("SELECT address, id as meter_id, '${headers.status}' as status_text , latitude, longitude FROM meter where id = '${headers.meterId}' ;"))
        .log("SQL SELECT statement: ${body}")
            .to("jdbc:dataSource")
            .marshal().json()
        .to("kafka:{{consumer.topic}}?brokers={{kafka.host}}:{{kafka.port}}")
    ;
----

. Check revision was added.

. In the CodeReady terminal, send a request to make sure everything works correctly
[source,bash,role="copypaste"]
----
TIMESTAMP=`date +%s`
curl -X POST \
http://meter-consumer-user1.apps.cluster-3bc2.3bc2.example.opentlc.com/meter/status \
-H 'content-type: application/json' \
-d '
     {
        "key": "F6PeB2XQRYG-8EN5yFcrP",
        "value": {"meterId":"F6PeB2XQRYG-8EN5yFcrP","timestamp":'$TIMESTAMP',"status":"unknown"}
      }
'
----

. Verify data was sent to the topic.


[type=verification]
Did you receive a JSON response from the Kafka HTTP Bridge that is similar to the provided example?

[type=verificationFail]
{standard-fail-text}


[time=10]
[id="Scaling up"]
== Scaling up with Serving



=== Starting the function with scaling options

 Knative Pod Autoscaler (KPA)
* Part of the Knative Serving core and enabled by default once Knative Serving is installed.
* Does not support CPU-based autoscaling.

 Horizontal Pod Autoscaler (HPA)
* Not part of the Knative Serving core, and must be enabled after Knative Serving installation.
* Does not support scale to zero functionality.
* Supports CPU-based autoscaling.


. In CodeReady, let run the Meter Consumer again with the new scaling setting using Camel K traits. It configure options when running the integration as Knative service.

[source,bash,role="copypaste"]
----
kamel run MeterConsumer.java -t knative-service.min-scale=0 -t knative-service.max-scale=5 -t knative-service.autoscaling-metric=concurrency -t knative-service.autoscaling-class=kpa.autoscaling.knative.dev -t knative-service.autoscaling-target=70
----

. Let's run the application with larger traffics
[source,bash,role="copypaste"]
----
kamel run Sender.java
----

. Go back to OpenShift Developer Console, and see if the pods has scaled up in order to serve the demands.


. Go to the UI and view the updated result.

[type=verification]
Did it scale up?

[type=verificationFail]
{standard-fail-text}


[time=5]
[id="summary"]
== Summary

In this lab you successfully xxxx
You can now proceed to link:{next-lab-url}[Lab 2].

[time=4]
[id="further-reading"]
== Notes and Further Reading

* xxxx
* xxxx
* xxxx
